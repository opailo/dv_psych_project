{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/opailo/dv_psych_project/blob/main/main_script/Psych_Project_Final_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBVIOfq7LFlV"
      },
      "outputs": [],
      "source": [
        "import PIL.Image, PIL.ImageFont, PIL.ImageDraw\n",
        "import os\n",
        "from random import shuffle\n",
        "import csv\n",
        "import pandas as pd \n",
        "from itertools import cycle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwXOx8e7KiEy"
      },
      "source": [
        "# Key for file names \n",
        "\n",
        "* idx 0 = Race + Gender + Expressor Number \n",
        "* idx 1 = irrelevant for project\n",
        "* idx 2 = Posture\n",
        "* idx 3 = Gender\n",
        "* idx 4 = Scene"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kxe0Pe0g5xz0"
      },
      "outputs": [],
      "source": [
        "directory = 'C:/Users/Otavio/Videos/FPCFull/'\n",
        "fd = 'C:/Users/Otavio/Videos/final_directory/'\n",
        "\n",
        "fpc_combos_list = ['Disgust_Anger_Sadness',\n",
        "                   'Anger_Disgust_Sadness',\n",
        "                   'Sadness_Fear_Hoy',\n",
        "                   'Fear_Anger_Disgust',\n",
        "                   'Hoy_Sadness_Fear',\n",
        "                   'Neutral_Disgust_Anger',\n",
        "                   'Neutral_Disgust_Hoy',\n",
        "                   'Neutral_Disgust_Sadness',\n",
        "                   'Neutral_Hoy_Anger',\n",
        "                   'Disgust_Anger_Anger',\n",
        "                   'Anger_Disgust_Disgust',\n",
        "                   'Anger_Fear_Hoy',\n",
        "                   'Anger_Fear_Sadness',\n",
        "                   'Sadness_Fear_Neutral',\n",
        "                   'Disgust_Disgust_Disgust',\n",
        "                   'Hoy_Hoy_Hoy',\n",
        "                   'Fear_Fear_Fear',\n",
        "                   'Anger_Anger_Anger',\n",
        "                   'Sadness_Sadness_Sadness',\n",
        "                   'Neutral_Neutral_Neutral']\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Js02xx3x1VEK"
      },
      "outputs": [],
      "source": [
        "def split_fpc_combos(fpc_combos_list):\n",
        "  ''' \n",
        "  Splits the list of fpc combos by underscore and returns a list containing the split fpc's\n",
        "  '''\n",
        "  split_fpc_combos_list = []\n",
        "\n",
        "  for fpc in fpc_combos_list:\n",
        "    split_fpc_combos_list.append(fpc.split('_'))\n",
        "\n",
        "  return split_fpc_combos_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7BCDoJP34qr"
      },
      "outputs": [],
      "source": [
        "def display_image(image_path):\n",
        "  \"\"\"\n",
        "  Function for displaying image \n",
        "  \"\"\"\n",
        "  \n",
        "  displayed_image = PIL.Image.open(image_path)\n",
        "\n",
        "  return displayed_image \n",
        "  # return displayed_image.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkE1cqpSCXKW"
      },
      "outputs": [],
      "source": [
        "# Places image paths into a list and return\n",
        "def file_path_list_generator(directory):\n",
        "  \"\"\"\n",
        "  This is going to place the full image paths into one list and \n",
        "  place the the individual file names into a seperate list \n",
        "  \"\"\"\n",
        "  file_paths_list = []\n",
        "  file_names_list = []\n",
        "\n",
        "  for filename in os.listdir(directory):\n",
        "      f = os.path.join(directory, filename)\n",
        "\n",
        "      if os.path.isfile(f):\n",
        "        file_paths_list.append(f)\n",
        "        file_names_list.append(filename)\n",
        "\n",
        "  return file_paths_list, file_names_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSgjsCTlDr2H"
      },
      "outputs": [],
      "source": [
        "def split_file_names(file_names_list):\n",
        "  \"\"\"\n",
        "  This is going to split the file names into it's components and place them in individual lists \n",
        "  which will then be appended to new_list\n",
        "  So file 'AM03_FO_Anger_Male_Joy5.jpg' will be ['AM03', 'FO', 'Anger', 'Male', 'Joy5']\n",
        "  \"\"\"\n",
        "\n",
        "  split_file_names_list = []\n",
        "  for filename in file_names_list:\n",
        "    split_file_names_list.append(filename.replace('.jpg', '').split('_'))\n",
        "\n",
        "  return split_file_names_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r03qjfzM-_nN"
      },
      "outputs": [],
      "source": [
        "def create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race, participant_gender):\n",
        "  '''\n",
        "  This function creates the base dataset based on the participant's race and gender \n",
        "\n",
        "  Race is denoted by: A, B, H, W\n",
        "  Gender is denoted by: M, F, O\n",
        "  '''\n",
        "  dataset_indexes = []\n",
        "  pre_final_dataset = []\n",
        "\n",
        "  # Loops through split_file_names_list and checks if Race and Gender matches \n",
        "  for filename in split_file_names_list: \n",
        "    if filename[0][0] == participant_race and filename[0][1] == participant_gender:\n",
        "      # Appends the indices of the file_names that pass the conditions\n",
        "      dataset_indexes.append(split_file_names_list.index(filename))\n",
        "\n",
        "  # Shuffles the indices\n",
        "  shuffle(dataset_indexes)\n",
        "  shuffled_dataset_indexes = dataset_indexes\n",
        "\n",
        "  i = 0\n",
        "\n",
        "  while i < len(shuffled_dataset_indexes) - 1:\n",
        "    # expressor condition, posture condition, scene condition\n",
        "    if split_file_names_list[shuffled_dataset_indexes[i]][0][2] + split_file_names_list[shuffled_dataset_indexes[i]][0][3] != split_file_names_list[shuffled_dataset_indexes[i+1]][0][2] + split_file_names_list[shuffled_dataset_indexes[i+1]][0][3] and split_file_names_list[shuffled_dataset_indexes[i]][2] != split_file_names_list[shuffled_dataset_indexes[i+1]][2] and split_file_names_list[shuffled_dataset_indexes[i]][4] != split_file_names_list[shuffled_dataset_indexes[i+1]][4]:\n",
        "      pre_final_dataset.append(file_paths_list[shuffled_dataset_indexes[i]])\n",
        "    i+=1\n",
        "\n",
        "\n",
        "  return pre_final_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYPlkMqfeIV5"
      },
      "outputs": [],
      "source": [
        "def create_final_dataset(pre_final_dataset, fpc_combos_list):\n",
        "  \n",
        "  temp_filename_list = []\n",
        "  final_dataset = []\n",
        "\n",
        "  #Splits the fpc combos list by underscores into a new list\n",
        "  split_fpc_combos_list = split_fpc_combos(fpc_combos_list)\n",
        "\n",
        "  # Removes the directory from the filenames in the files in the pre_final_dataset\n",
        "  # Remember that this is the shuffled dataset that has already been sorted for:\n",
        "    # Race, gender, and makes sure that there aren't any duplicates in terms of posture, face, and backgrounds\n",
        "  for filename in pre_final_dataset:\n",
        "    temp_filename_list.append(filename.replace(directory, \"\"))\n",
        "\n",
        "  # Splits the filenames by underscore\n",
        "  split_temp_filename_list = split_file_names(temp_filename_list)\n",
        "\n",
        "  # Loops through the fpc combos and checks them with their respective counterparts in the filenames\n",
        "  # Adds file names that pass the conditions \n",
        "  #Conditions:\n",
        "    # Condition 1: First letters of fpc for Face FPC must match\n",
        "    # Condition 2: Posture FPC must match\n",
        "    # Conditon 3: First letters for scene FPC must match\n",
        "  for fpc in split_fpc_combos_list:\n",
        "    for file_name in split_temp_filename_list:\n",
        "      if fpc[0][0] == file_name[1][0] and fpc[1] == file_name[2] and fpc[2][0] == file_name[4][0]:\n",
        "        final_dataset.append( pre_final_dataset[split_temp_filename_list.index(file_name)] )\n",
        "        break\n",
        "  return final_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPkBmywgQPAW"
      },
      "outputs": [],
      "source": [
        "def only_gender_is_other(directory, true_r):\n",
        "      if true_r == 'A':\n",
        "        #Creates first set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='A', participant_gender='M')\n",
        "\n",
        "        final_dataset_1 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        #Creates second set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='A', participant_gender='M')\n",
        "        final_dataset_2 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        #Creates third set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='A', participant_gender='M')\n",
        "        final_dataset_3 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        #Creates fourth set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='A', participant_gender='F')\n",
        "        final_dataset_4 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        #Creates fith set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='A', participant_gender='F')\n",
        "        final_dataset_5 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        #Creates sixth set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='A', participant_gender='F')\n",
        "        final_dataset_6 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        # Combines the final_datasets together\n",
        "        full_dataset = final_dataset_1 + final_dataset_2 + final_dataset_3 + final_dataset_4 + final_dataset_5 + final_dataset_6\n",
        "\n",
        "        # Shuffles the combined set\n",
        "        shuffle(full_dataset)\n",
        "\n",
        "        dataset = []\n",
        "\n",
        "        # Loops through the full dataset and removes any duplicates and any excess files\n",
        "        for file_paths in full_dataset:\n",
        "          if file_paths not in dataset:\n",
        "            dataset.append(file_paths)\n",
        "\n",
        "        return dataset\n",
        "\n",
        "      elif true_r == 'B':\n",
        "        #Creates first set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='B', participant_gender='M')\n",
        "\n",
        "        final_dataset_1 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        #Creates second set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='B', participant_gender='M')\n",
        "        final_dataset_2 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        #Creates third set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='B', participant_gender='M')\n",
        "        final_dataset_3 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        #Creates fourth set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='B', participant_gender='F')\n",
        "        final_dataset_4 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        #Creates fith set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='B', participant_gender='F')\n",
        "        final_dataset_5 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        #Creates sixth set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='B', participant_gender='F')\n",
        "        final_dataset_6 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        # Combines the final_datasets together\n",
        "        full_dataset = final_dataset_1 + final_dataset_2 + final_dataset_3 + final_dataset_4 + final_dataset_5 + final_dataset_6\n",
        "\n",
        "        # Shuffles the combined set\n",
        "        shuffle(full_dataset)\n",
        "\n",
        "        dataset = []\n",
        "\n",
        "        # Loops through the full dataset and removes any duplicates and any excess files\n",
        "        for file_paths in full_dataset:\n",
        "          if file_paths not in dataset:\n",
        "            dataset.append(file_paths)\n",
        "\n",
        "        return dataset\n",
        "\n",
        "      elif true_r == 'H':\n",
        "        #Creates first set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='H', participant_gender='M')\n",
        "        final_dataset_1 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "\n",
        "        #Creates second set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='H', participant_gender='M')\n",
        "        final_dataset_2 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        #Creates third set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='H', participant_gender='M')\n",
        "        final_dataset_3 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        #Creates fourth set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='H', participant_gender='F')\n",
        "        final_dataset_4 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        #Creates fith set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='H', participant_gender='F')\n",
        "        final_dataset_5 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        #Creates sixth set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='H', participant_gender='F')\n",
        "        final_dataset_6 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        # Combines the final_datasets together\n",
        "        full_dataset = final_dataset_1 + final_dataset_2 + final_dataset_3 + final_dataset_4 + final_dataset_5 + final_dataset_6\n",
        "\n",
        "        # Shuffles the combined set\n",
        "        shuffle(full_dataset)\n",
        "\n",
        "        dataset = []\n",
        "\n",
        "        # Loops through the full dataset and removes any duplicates and any excess files\n",
        "        for file_paths in full_dataset:\n",
        "          if file_paths not in dataset:\n",
        "            dataset.append(file_paths)\n",
        "\n",
        "        return dataset\n",
        "\n",
        "      elif true_r == 'W':\n",
        "        #Creates first set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='W', participant_gender='M')\n",
        "\n",
        "        final_dataset_1 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        #Creates second set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='W', participant_gender='M')\n",
        "        final_dataset_2 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        #Creates third set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='W', participant_gender='M')\n",
        "        final_dataset_3 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        #Creates fourth set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='W', participant_gender='F')\n",
        "        final_dataset_4 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        #Creates fith set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='W', participant_gender='F')\n",
        "        final_dataset_5 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        #Creates sixth set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='W', participant_gender='F')\n",
        "        final_dataset_6 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        # Combines the final_datasets together\n",
        "        full_dataset = final_dataset_1 + final_dataset_2 + final_dataset_3 + final_dataset_4 + final_dataset_5 + final_dataset_6\n",
        "\n",
        "        # Shuffles the combined set\n",
        "        shuffle(full_dataset)\n",
        "\n",
        "        dataset = []\n",
        "\n",
        "        # Loops through the full dataset and removes any duplicates and any excess files\n",
        "        for file_paths in full_dataset:\n",
        "          if file_paths not in dataset:\n",
        "            dataset.append(file_paths)\n",
        "\n",
        "        return dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQNlpQ6pNLMl"
      },
      "outputs": [],
      "source": [
        "def only_race_is_other(directory, true_g):\n",
        "      if true_g == 'M':\n",
        "        #Creates first set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='A', participant_gender='M')\n",
        "        final_dataset_1 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        #Creates second set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='B', participant_gender='M')\n",
        "        final_dataset_2 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        #Creates third set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='H', participant_gender='M')\n",
        "        final_dataset_3 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        #Creates fourth set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='W', participant_gender='M')\n",
        "        final_dataset_4 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        #Creates fifth set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='A', participant_gender='M')\n",
        "        final_dataset_5 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        #Creates sixth set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='B', participant_gender='M')\n",
        "        final_dataset_6 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        #Creates seventh set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='H', participant_gender='M')\n",
        "        final_dataset_7 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        #Creates eighth set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='W', participant_gender='M')\n",
        "        final_dataset_8 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        # Combines the final_datasets together\n",
        "        full_dataset = final_dataset_1 + final_dataset_2 + final_dataset_3 + final_dataset_4 + final_dataset_5 + final_dataset_6 + final_dataset_7 + final_dataset_8\n",
        "\n",
        "        # Shuffles the combined set\n",
        "        shuffle(full_dataset)\n",
        "\n",
        "        dataset = []\n",
        "\n",
        "        # Loops through the full dataset and removes any duplicates and any excess files\n",
        "        for file_paths in full_dataset:\n",
        "          if file_paths not in dataset:\n",
        "            dataset.append(file_paths)\n",
        "\n",
        "        return dataset\n",
        "\n",
        "      elif true_g == 'F':\n",
        "        #Creates first set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='A', participant_gender='F')\n",
        "        final_dataset_1 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        #Creates second set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='B', participant_gender='F')\n",
        "        final_dataset_2 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        #Creates third set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='H', participant_gender='F')\n",
        "        final_dataset_3 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        #Creates fourth set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='W', participant_gender='F')\n",
        "        final_dataset_4 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        #Creates fith set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='A', participant_gender='F')\n",
        "        final_dataset_5 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        #Creates sixth set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='B', participant_gender='F')\n",
        "        final_dataset_6 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        #Creates seventh set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='H', participant_gender='F')\n",
        "        final_dataset_7 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "        #Creates eigth set\n",
        "        file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "        split_file_names_list = split_file_names(file_names_list)\n",
        "        pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='W', participant_gender='F')\n",
        "        final_dataset_8 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "        \n",
        "        # Combines the final_datasets together\n",
        "        full_dataset = final_dataset_1 + final_dataset_2 + final_dataset_3 + final_dataset_4 + final_dataset_5 + final_dataset_6 + final_dataset_7 + final_dataset_8\n",
        "     \n",
        "        # Shuffles the combined set\n",
        "        shuffle(full_dataset)\n",
        "\n",
        "        dataset = []\n",
        "\n",
        "        # Loops through the full dataset and removes any duplicates and any excess files\n",
        "        for file_paths in full_dataset:\n",
        "          if file_paths not in dataset:\n",
        "            dataset.append(file_paths)\n",
        "\n",
        "        return dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6acjGY4IaRy"
      },
      "outputs": [],
      "source": [
        "def both_are_other(directory):\n",
        "      #Creates first set\n",
        "      file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "      split_file_names_list = split_file_names(file_names_list)\n",
        "      pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='A', participant_gender='M')\n",
        "      final_dataset_1 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "      #Creates second set\n",
        "      file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "      split_file_names_list = split_file_names(file_names_list)\n",
        "      pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='B', participant_gender='M')\n",
        "      final_dataset_2 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "      #Creates third set\n",
        "      file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "      split_file_names_list = split_file_names(file_names_list)\n",
        "      pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='H', participant_gender='M')\n",
        "      final_dataset_3 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "      #Creates fourth set\n",
        "      file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "      split_file_names_list = split_file_names(file_names_list)\n",
        "      pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='W', participant_gender='M')\n",
        "      final_dataset_4 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "      #Creates fith set\n",
        "      file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "      split_file_names_list = split_file_names(file_names_list)\n",
        "      pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='A', participant_gender='F')\n",
        "      final_dataset_5 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "      #Creates sixth set\n",
        "      file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "      split_file_names_list = split_file_names(file_names_list)\n",
        "      pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='B', participant_gender='F')\n",
        "      final_dataset_6 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "      #Creates seventh set\n",
        "      file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "      split_file_names_list = split_file_names(file_names_list)\n",
        "      pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='H', participant_gender='F')\n",
        "      final_dataset_7 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "      #Creates eigth set\n",
        "      file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "      split_file_names_list = split_file_names(file_names_list)\n",
        "      pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race='W', participant_gender='F')\n",
        "      final_dataset_8 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "      # Combines the final_datasets together\n",
        "      full_dataset = final_dataset_1 + final_dataset_2 + final_dataset_3 + final_dataset_4 + final_dataset_5 + final_dataset_6 + final_dataset_7 + final_dataset_8\n",
        "\n",
        "      # Shuffles the combined set\n",
        "      shuffle(full_dataset)\n",
        "\n",
        "      dataset = []\n",
        "\n",
        "      # Loops through the full dataset and removes any duplicates and any excess files\n",
        "      for file_paths in full_dataset:\n",
        "        if file_paths not in dataset:\n",
        "          dataset.append(file_paths)\n",
        "\n",
        "      return dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygGIt6yt16qt"
      },
      "outputs": [],
      "source": [
        "def dataset(directory, participant_race, participant_gender):\n",
        "    '''\n",
        "    This is going to combine 'final datasets' together, shuffle it, and returns a dataset\n",
        "    ''' \n",
        "\n",
        "\n",
        "    if participant_gender == 'O' and participant_race != 'O':\n",
        "      true_r = participant_race\n",
        "      dataset = only_gender_is_other(directory, true_r)\n",
        "      return dataset\n",
        "\n",
        "\n",
        "    \n",
        "    elif participant_race == 'O' and participant_gender != 'O':\n",
        "      true_g = participant_race\n",
        "      dataset = only_race_is_other(directory, true_g)\n",
        "      return dataset\n",
        "\n",
        "\n",
        "\n",
        "    elif participant_gender == 'O' and participant_race == 'O':\n",
        "      dataset = both_are_other(directory)\n",
        "      return dataset\n",
        "\n",
        "    \n",
        "    else:\n",
        "      #Creates first set\n",
        "      file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "      split_file_names_list = split_file_names(file_names_list)\n",
        "      pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race, participant_gender)\n",
        "      final_dataset_1 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "      #Creates second set\n",
        "      file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "      split_file_names_list = split_file_names(file_names_list)\n",
        "      pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race, participant_gender)\n",
        "      final_dataset_2 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "      #Creates third set\n",
        "      file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "      split_file_names_list = split_file_names(file_names_list)\n",
        "      pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race, participant_gender)\n",
        "      final_dataset_3 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "      #Creates fourth set\n",
        "      file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "      split_file_names_list = split_file_names(file_names_list)\n",
        "      pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race, participant_gender)\n",
        "      final_dataset_4 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "      #Creates fith set\n",
        "      file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "      split_file_names_list = split_file_names(file_names_list)\n",
        "      pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race, participant_gender)\n",
        "      final_dataset_5 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "      #Creates sixth set\n",
        "      file_paths_list, file_names_list = file_path_list_generator(directory)\n",
        "      split_file_names_list = split_file_names(file_names_list)\n",
        "      pre_final_dataset = create_pre_final_dataset(file_paths_list, split_file_names_list, participant_race, participant_gender)\n",
        "      final_dataset_6 = create_final_dataset(pre_final_dataset, fpc_combos_list)\n",
        "\n",
        "      # Combines the final_datasets together\n",
        "      full_dataset = final_dataset_1 + final_dataset_2 + final_dataset_3 + final_dataset_4 + final_dataset_5 + final_dataset_6\n",
        "\n",
        "      # Shuffles the combined set\n",
        "      shuffle(full_dataset)\n",
        "\n",
        "      dataset = []\n",
        "\n",
        "      # Loops through the full dataset and removes any duplicates and any excess files\n",
        "      for file_paths in full_dataset:\n",
        "        if file_paths not in dataset:\n",
        "          dataset.append(file_paths)\n",
        "\n",
        "      return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6u04XYL4sMl"
      },
      "outputs": [],
      "source": [
        "def condition_checker(ls):\n",
        "  i = 0\n",
        "\n",
        "  conditions = []\n",
        "  condition = 'Bad'\n",
        "  licycle = cycle(ls)\n",
        "\n",
        "  # Prime the pump\n",
        "  nextelem = next(licycle)\n",
        "\n",
        "  while i <= len(ls) - 1:\n",
        "      thiselem, nextelem = nextelem, next(licycle)\n",
        "\n",
        "      conditions.append(thiselem[1][0] == nextelem[1][0] or thiselem[2][0] == nextelem[2][0] or thiselem[4] == nextelem[4])\n",
        "      i += 1\n",
        "  return conditions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iuv9vvG4sMl"
      },
      "outputs": [],
      "source": [
        "def generate_non_repeat(ds, participant_race, participant_gender):\n",
        "  file_names_list = []\n",
        "\n",
        "  for file_path in ds:\n",
        "    file_name = file_path.replace(directory, '')\n",
        "    file_names_list.append(file_name) \n",
        "\n",
        "  file_names_list = split_file_names(file_names_list)\n",
        "\n",
        "  ls = file_names_list\n",
        "\n",
        "\n",
        "\n",
        "  conditions = condition_checker(ls)\n",
        "  last_list_hopefully = []\n",
        "\n",
        "  i=0\n",
        "\n",
        "  while i < len(ls):\n",
        "    if conditions[i] == False:\n",
        "        last_list_hopefully.append(ls[i])\n",
        "    i+=1\n",
        "\n",
        "  conditions = condition_checker(last_list_hopefully)\n",
        "  determiner = True\n",
        "\n",
        "  for condition in conditions[:20]:\n",
        "    if condition == True:\n",
        "      determiner = False\n",
        "      break\n",
        "    else: \n",
        "      determiner = True\n",
        "      last_list_hopefully = last_list_hopefully[:19]\n",
        "  \n",
        "  return determiner, last_list_hopefully\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2iCsZoH4sMm"
      },
      "outputs": [],
      "source": [
        "def tls_generator(directory, participant_race, participant_gender):\n",
        "  determiner = False\n",
        "  true_g = participant_gender \n",
        "\n",
        "  if participant_race == 'O' and participant_gender != 'O':\n",
        "    while determiner == False:\n",
        "      red = only_race_is_other(directory, true_g)\n",
        "      determiner, llh = generate_non_repeat(red, 'O', true_g)\n",
        "\n",
        "  else:\n",
        "    while determiner == False:\n",
        "      ds = dataset(directory, participant_race, participant_gender)\n",
        "      determiner, llh = generate_non_repeat(ds, participant_race, participant_gender)\n",
        "\n",
        "  llh = llh\n",
        "\n",
        "\n",
        "  llh_to_xlsx = []\n",
        "\n",
        "  for f_name in llh:\n",
        "    llh_to_xlsx.append(('_'.join(f_name)) + '.jpg')\n",
        "\n",
        "  \n",
        "  df = pd.DataFrame()\n",
        "    \n",
        "  # Creating two columns\n",
        "  df['file_path'] = llh_to_xlsx\n",
        "\n",
        "  # Converting to excel\n",
        "\n",
        "  return df.to_excel(fd + f'{participant_race}{participant_gender}.xlsx', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9SLHHPw4sMm"
      },
      "outputs": [],
      "source": [
        "tls_generator(directory, participant_race='B', participant_gender='F')\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "c0302f08080d2957537319669d88f431fe0a3280ce3fe25829523ba3e2f4c24c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}